# -*- coding: utf-8 -*-
"""Samar Portfolio

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O_DVH4W5C4CzyMeTbWgeTkDExpmZw3jv

#Importing the Dataset and the necessary Libararies
"""

from google.colab import files 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statistics

uploaded = files.upload()

"""#Pandas DataFrames Reading
calling the library with the needed function to read the data from an excel file 
"""

DF = pd.read_csv('Music and Mental Health.csv')
DF

"""# Statistics

Python has a built in statistics package that allows you do some basic descriptive statistics like mean, standard deviation and variance.


"""

import statistics
import numpy as np

# List of DataFrame Built in Functions then Describe
print(DF.var())
print(DF.mean())
print(DF.value_counts())
print(DF.describe())

uploaded = files.upload()

DF1 = pd.read_csv('Music and Mental Health.csv')
DF1

print(DF1.mean())
print(DF.describe())

uploaded1 = files.upload()

DF2 = pd.read_csv('Music and Mental Health.csv')
DF2

DF2.describe()

"""# Shapiro test:
The Shapiroâ€“Wilk test is essentially a goodness-of-fit test. That is, it examines how close the sample data fit to a normal distribution. It does this by ordering and standardizing the sample (standardizing refers to converting the data to a distribution with mean and standard deviation ).
Since the Shapiro test is used to describe the normality of data, if the p-value is less then 0.5, we can tell that data is non-normal and reject the null hypothesis, but in our case the p-value is close to 1 which means our data is normally distributed
"""

DF = pd.read_csv('Music and Mental Health.csv')
DF

fig, ax = plt.subplots(figsize =(10, 7))
ax.hist(DF2['Age'], bins = 10)
print(shapiro(DF2['Age']))
plt.show()

fig, ax = plt.subplots(figsize =(10, 7))
ax.hist(DF2['Anxiety'], bins = 10)
print(shapiro(DF2['Anxiety']))
plt.show()